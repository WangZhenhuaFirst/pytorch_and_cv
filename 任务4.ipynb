{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务4：PyTorch激活函数原理和使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sigmoid激活函数\n",
    "\n",
    "$ \\sigma (x) = \\frac{1}{1 + exp(-x)} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9526, 0.9526],\n",
      "        [0.9526, 0.9526]], dtype=torch.float64)\n",
      "tensor([[0.9526, 0.9526],\n",
      "        [0.9526, 0.9526]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(X):\n",
    "    return 1.0 / (1.0 + np.exp(-X))\n",
    "\n",
    "X = torch.full((2, 2), 3)\n",
    "res = sigmoid(X)\n",
    "print(res)\n",
    "print(torch.sigmoid(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogSigmoid激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.2914, -0.5529])\n",
      "tensor([-2.3877, -1.0073])\n",
      "tensor([-2.3877, -1.0073])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def log_sigmoid(X):\n",
    "    return np.log(1.0 / (1 + np.exp(-X)))\n",
    "    \n",
    "               \n",
    "X = torch.randn(2)\n",
    "print(X)\n",
    "print(log_sigmoid(X))\n",
    "m = torch.nn.LogSigmoid()\n",
    "print(m(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tanh激活函数\n",
    "\n",
    "$ tanh(x) = \\frac{exp(x) - exp(-x)}{exp(x) + exp(-x)} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1, 12, 23, 34, 45, 56, 67, 78, 89])\n",
      "tensor([0.7616, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       dtype=torch.float64)\n",
      "tensor([0.7616, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def tanh(X):\n",
    "    return (np.exp(X) - np.exp(-X)) / (np.exp(X) + np.exp(-X))\n",
    "\n",
    "X1 = torch.arange(1, 100, 11)\n",
    "print(X1)\n",
    "print(tanh(X1))\n",
    "print(torch.tanh(X1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tanhshrink激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1, 12, 23, 34, 45, 56, 67, 78, 89])\n",
      "tensor([ 0.2384, 11.0000, 22.0000, 33.0000, 44.0000, 55.0000, 66.0000, 77.0000,\n",
      "        88.0000], dtype=torch.float64)\n",
      "tensor([ 0.2384, 11.0000, 22.0000, 33.0000, 44.0000, 55.0000, 66.0000, 77.0000,\n",
      "        88.0000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def tanh_shrink(X):\n",
    "    return X - (np.exp(X) - np.exp(-X)) / (np.exp(X) + np.exp(-X))\n",
    "\n",
    "X = torch.arange(1, 100, 11)\n",
    "print(X)\n",
    "print(tanh_shrink(X))\n",
    "m = torch.nn.Tanhshrink()\n",
    "print(m(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5113, -1.0381,  1.1041],\n",
      "        [-0.7594,  0.4174, -0.4723]])\n",
      "tensor([[0.5113, 0.0000, 1.1041],\n",
      "        [0.0000, 0.4174, 0.0000]])\n",
      "tensor([[0.5113, 0.0000, 1.1041],\n",
      "        [0.0000, 0.4174, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def relu(X):\n",
    "    X = np.where(X>=0, X, 0)\n",
    "    return torch.tensor(X)\n",
    "X = torch.randn(2, 3)\n",
    "print(X)\n",
    "print(relu(X))\n",
    "print(torch.relu(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeakyReLU 激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.7487,  0.8466, -0.3841],\n",
      "        [-0.7913, -0.0664,  0.4261]])\n",
      "tensor([[ 1.7487,  0.8466, -0.0768],\n",
      "        [-0.1583, -0.0133,  0.4261]])\n",
      "tensor([[ 1.7487,  0.8466, -0.0768],\n",
      "        [-0.1583, -0.0133,  0.4261]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def leakyrelu(X, gamma):\n",
    "    X = np.where(X>0, X, X*gamma)\n",
    "    return torch.tensor(X)\n",
    "\n",
    "X = torch.randn(2, 3)\n",
    "print(X)\n",
    "print(leakyrelu(X, 0.2))\n",
    "print(torch.nn.functional.leaky_relu(X, 0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELU激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2701, -0.8940, -0.6079],\n",
      "        [-0.6608,  2.0310, -0.0056]])\n",
      "tensor([[ 1.2701e+00, -5.9097e-02, -4.5550e-02],\n",
      "        [-4.8356e-02,  2.0310e+00, -5.5551e-04]])\n",
      "tensor([[ 1.2701e+00, -5.9097e-02, -4.5550e-02],\n",
      "        [-4.8356e-02,  2.0310e+00, -5.5551e-04]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def fun_elu(X, gamma):\n",
    "    X = np.where(X>0, X, gamma * (np.exp(X) - 1))\n",
    "    return torch.tensor(X)\n",
    "\n",
    "X = torch.randn(2, 3)\n",
    "print(X)\n",
    "print(fun_elu(X, 0.1))\n",
    "print(torch.nn.functional.elu(X, 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PReLU 激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.7817, -0.8233])\n",
      "tensor([-0.8909, -0.4116])\n",
      "tensor([-0.8909, -0.4116], grad_fn=<PreluBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def prelu(X, a):\n",
    "    X = np.where(X >= 0, X, a * X)\n",
    "    return torch.tensor(X)\n",
    "\n",
    "X = torch.randn(2)\n",
    "print(X)\n",
    "print(prelu(X, 0.5))\n",
    "m = torch.nn.PReLU(init=0.5)\n",
    "print(m(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReLU6 激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-10,  -9,  -8,  -7,  -6,  -5,  -4,  -3,  -2,  -1,   0,   1,   2,   3,\n",
      "          4,   5,   6,   7,   8,   9])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 3, 4, 5, 6, 6, 6, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 3, 4, 5, 6, 6, 6, 6])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def fun_relu6(X):\n",
    "    X = np.where(X < 0, 0, X)\n",
    "    X = np.where(X > 6, 6, X)\n",
    "    return torch.tensor(X)\n",
    "\n",
    "X = torch.arange(-10, 10)\n",
    "print(X)\n",
    "print(fun_relu6(X))\n",
    "m = torch.nn.ReLU6()\n",
    "m(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SELU 激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3241,  0.1413,  0.3136],\n",
      "        [-3.0396,  0.0296,  1.1961]])\n",
      "tensor([[ 0.3405,  0.1485,  0.3295],\n",
      "        [-1.6740,  0.0311,  1.2567]])\n",
      "tensor([[ 0.3405,  0.1485,  0.3295],\n",
      "        [-1.6740,  0.0311,  1.2567]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def func_selu(X):\n",
    "    return scale * (np.maximum(0, X) + np.minimum(0, alpha * (np.exp(X) - 1)))\n",
    "    \n",
    "    \n",
    "scale = 1.0507009873554804934193349852946\n",
    "alpha = 1.6732632423543772848170429916717\n",
    "X = torch.randn(2, 3)\n",
    "print(X)\n",
    "print(func_selu(X))\n",
    "m = torch.nn.SELU()\n",
    "print(m(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CELU 激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1051, -1.6713, -1.0235],\n",
      "        [ 0.3085, -1.1956, -0.5194]])\n",
      "tensor([[ 0.1051, -0.8120, -0.6407],\n",
      "        [ 0.3085, -0.6975, -0.4051]])\n",
      "tensor([[ 0.1051, -0.8120, -0.6407],\n",
      "        [ 0.3085, -0.6975, -0.4051]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def fun_celu(X):\n",
    "    return np.maximum(X, 0) + np.minimum(np.exp(X) - 1, 0)\n",
    "    \n",
    "X = torch.randn(2, 3)\n",
    "print(X)\n",
    "print(fun_celu(X))\n",
    "m = torch.nn.CELU()\n",
    "print(m(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softplus 激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5749,  0.0425, -0.2328],\n",
      "        [-1.0626, -1.1710, -0.3878]])\n",
      "tensor([[1.0213, 0.7146, 0.5835],\n",
      "        [0.2968, 0.2701, 0.5179]])\n",
      "tensor([[1.0213, 0.7146, 0.5835],\n",
      "        [0.2968, 0.2701, 0.5179]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def soft_plus(X):\n",
    "    return np.log(1 + np.exp(X))\n",
    "\n",
    "X = torch.randn(2, 3)\n",
    "print(X)\n",
    "print(soft_plus(X))\n",
    "m = torch.nn.Softplus()\n",
    "print(m(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SoftShrinkage 激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4655,  1.1551, -1.0290],\n",
      "        [ 1.5130, -1.1692, -0.6505]])\n",
      "tensor([[ 0.0000,  0.6551, -0.5290],\n",
      "        [ 1.0130, -0.6692, -0.1505]])\n",
      "tensor([[ 0.0000,  0.6551, -0.5290],\n",
      "        [ 1.0130, -0.6692, -0.1505]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def soft_shrinkage(X):\n",
    "    X = np.where((X <= 0.5) & (X >= -0.5), 0, X)\n",
    "    X = np.where(X > 0.5, X - 0.5, X)\n",
    "    X = np.where(X < -0.5, X + 0.5, X)\n",
    "    return torch.tensor(X)\n",
    "    \n",
    "X = torch.randn(2, 3)\n",
    "print(X)\n",
    "print(soft_shrinkage(X))\n",
    "m = torch.nn.Softshrink()\n",
    "print(m(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
